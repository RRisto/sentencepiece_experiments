{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sentencepiece as spm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is from Keelreressursside Keskusest: http://peeter.eki.ee:5000/valence/paragraphsquery/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4090"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=Path('data/raw/exportparagraphs').read_text().split('\\n')\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    pieces=row.split(',', 4)\n",
    "    if len(pieces)>=5:\n",
    "        return {'type':pieces[0], 'url':pieces[1], 'number':pieces[2], 'sentiment':pieces[3], 'text':pieces[4]}\n",
    "    else:\n",
    "        return {'type':'', 'url':'', 'number':'', 'sentiment':'', 'text':''}\n",
    "\n",
    "def process_rows(rows):\n",
    "    processed_rows=[process_row(row) for row in rows]\n",
    "    return pd.DataFrame(processed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4090, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=process_rows(rows)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>\"Enam kui kümme aastat tagasi tegutses huumori...</td>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>vastuoluline</td>\n",
       "      <td>\"Neid ridu kirjutades tundub isegi ebaviisakas...</td>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>positiivne</td>\n",
       "      <td>\"Isiklikult kohtasin natukegi Kukekese moodi p...</td>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>vastuoluline</td>\n",
       "      <td>\"Olen näinud ka, kuidas patrull korrarikkujat ...</td>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>negatiivne</td>\n",
       "      <td>\"Kummaline on nüüd äkki lugeda politsei ja sis...</td>\n",
       "      <td>ARVAMUS</td>\n",
       "      <td>http://arvamus.postimees.ee/1001520/anvar-samo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  number     sentiment                                               text  \\\n",
       "0      1    negatiivne  \"Enam kui kümme aastat tagasi tegutses huumori...   \n",
       "1      2  vastuoluline  \"Neid ridu kirjutades tundub isegi ebaviisakas...   \n",
       "2      3    positiivne  \"Isiklikult kohtasin natukegi Kukekese moodi p...   \n",
       "3      4  vastuoluline  \"Olen näinud ka, kuidas patrull korrarikkujat ...   \n",
       "4      5    negatiivne  \"Kummaline on nüüd äkki lugeda politsei ja sis...   \n",
       "\n",
       "      type                                                url  \n",
       "0  ARVAMUS  http://arvamus.postimees.ee/1001520/anvar-samo...  \n",
       "1  ARVAMUS  http://arvamus.postimees.ee/1001520/anvar-samo...  \n",
       "2  ARVAMUS  http://arvamus.postimees.ee/1001520/anvar-samo...  \n",
       "3  ARVAMUS  http://arvamus.postimees.ee/1001520/anvar-samo...  \n",
       "4  ARVAMUS  http://arvamus.postimees.ee/1001520/anvar-samo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negatiivne      1927\n",
       "positiivne       882\n",
       "neutraalne       727\n",
       "vastuoluline     552\n",
       "                   2\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make second dataset, keep only two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2809, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple=df[df.sentiment.isin(['negatiivne', 'positiivne'])]\n",
    "df_simple=df_simple.reset_index(drop=True)\n",
    "df_simple.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove empty lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4088, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df.text!='']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizers_files=list(Path('tokenizers/').glob('*.model'))\n",
    "len(tokenizers_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipe(tokenizer=None):\n",
    "    vectorizer=CountVectorizer(tokenizer=tokenizer) if tokenizer is not None else CountVectorizer()\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('clf', LinearSVC()) ])\n",
    "    return text_clf\n",
    "\n",
    "def cv_model(X, y, tokenizer, n_splits=10):\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    precs=[]\n",
    "    recs=[]\n",
    "    f1s=[]\n",
    "    y_tests=[]\n",
    "    cv_idx=[]\n",
    "    i=0\n",
    "    \n",
    "    for train, test in skf.split(X, y):\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        text_clf=make_pipe(tokenizer)\n",
    "        text_clf.fit(X_train, y_train)\n",
    "        pred=text_clf.predict(X_test)\n",
    "        prec, recall, f1, _ = precision_recall_fscore_support(y_test, pred, average='weighted')\n",
    "        precs.append(prec)\n",
    "        recs.append(recall)\n",
    "        f1s.append(f1)\n",
    "        cv_idx.append(i)\n",
    "        i+=1\n",
    "        \n",
    "    return pd.DataFrame({'precision':precs, 'recall':recs, 'f1':f1s, 'cv_i':cv_idx})\n",
    "\n",
    "def tokenizer_metrics(tokenizer_file, X, y):\n",
    "    if tokenizer_file is not None:\n",
    "        st = spm.SentencePieceProcessor()\n",
    "        st.Load(str(tokenizer_file))\n",
    "\n",
    "        df_tokenizer_metrics=cv_model(X, y, st.EncodeAsPieces)\n",
    "        df_tokenizer_metrics['tokenizer']=tokenizer_file\n",
    "    else:\n",
    "        df_tokenizer_metrics=cv_model(X, y, None)\n",
    "        df_tokenizer_metrics['tokenizer']='default_sklearn_tokenizer'\n",
    "    return df_tokenizer_metrics\n",
    "\n",
    "def tokenizers_metrics(tokenizer_files, X, y):\n",
    "    df_metrics_all=pd.DataFrame()\n",
    "    for file in tokenizer_files:\n",
    "        print(f'working on tokenizer {file}')\n",
    "        df_tokenizer_metrics=tokenizer_metrics(file, X, y)\n",
    "        df_metrics_all=df_metrics_all.append(df_tokenizer_metrics)\n",
    "    df_metrics_all=df_metrics_all.reset_index(drop=True)\n",
    "    return df_metrics_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#None is for default sklearn tokenizer, this is our baseline\n",
    "tokenizers_files_with_default=[None]+tokenizers_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "df_metrics_all = tokenizers_metrics(tokenizers_files_with_default, df.text, df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>cv_i</th>\n",
       "      <th>tokenizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369497</td>\n",
       "      <td>0.374083</td>\n",
       "      <td>0.368613</td>\n",
       "      <td>0</td>\n",
       "      <td>default_sklearn_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.419964</td>\n",
       "      <td>0.391198</td>\n",
       "      <td>0.401656</td>\n",
       "      <td>1</td>\n",
       "      <td>default_sklearn_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411638</td>\n",
       "      <td>0.422983</td>\n",
       "      <td>0.410133</td>\n",
       "      <td>2</td>\n",
       "      <td>default_sklearn_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.405747</td>\n",
       "      <td>0.430318</td>\n",
       "      <td>0.415472</td>\n",
       "      <td>3</td>\n",
       "      <td>default_sklearn_tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.406680</td>\n",
       "      <td>0.452323</td>\n",
       "      <td>0.418062</td>\n",
       "      <td>4</td>\n",
       "      <td>default_sklearn_tokenizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        f1  cv_i                  tokenizer\n",
       "0   0.369497  0.374083  0.368613     0  default_sklearn_tokenizer\n",
       "1   0.419964  0.391198  0.401656     1  default_sklearn_tokenizer\n",
       "2   0.411638  0.422983  0.410133     2  default_sklearn_tokenizer\n",
       "3   0.405747  0.430318  0.415472     3  default_sklearn_tokenizer\n",
       "4   0.406680  0.452323  0.418062     4  default_sklearn_tokenizer"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer None\n",
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_1000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_1000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_5000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_5000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_10000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_10000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/unigram_vocab_size_20000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nmt_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nfkc.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nmt_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_nfkc_cf.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on tokenizer tokenizers/bpe_vocab_size_20000_norm_identity.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/v36torch1.1.0/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "df_metrics_all_simple = tokenizers_metrics(tokenizers_files_with_default, df_simple.text, df_simple.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_1000_norm_nfkc.model</th>\n",
       "      <td>0.421593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_10000_norm_identity.model</th>\n",
       "      <td>0.419265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_1000_norm_nmt_nfkc.model</th>\n",
       "      <td>0.418405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_5000_norm_nfkc.model</th>\n",
       "      <td>0.417930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_5000_norm_nmt_nfkc.model</th>\n",
       "      <td>0.417743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default_sklearn_tokenizer</th>\n",
       "      <td>0.416767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_5000_norm_identity.model</th>\n",
       "      <td>0.415190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_1000_norm_identity.model</th>\n",
       "      <td>0.414394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_1000_norm_nfkc.model</th>\n",
       "      <td>0.413803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_1000_norm_identity.model</th>\n",
       "      <td>0.413796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          f1\n",
       "tokenizer                                                   \n",
       "tokenizers/unigram_vocab_size_1000_norm_nfkc.model  0.421593\n",
       "tokenizers/bpe_vocab_size_10000_norm_identity.m...  0.419265\n",
       "tokenizers/unigram_vocab_size_1000_norm_nmt_nfk...  0.418405\n",
       "tokenizers/bpe_vocab_size_5000_norm_nfkc.model      0.417930\n",
       "tokenizers/bpe_vocab_size_5000_norm_nmt_nfkc.model  0.417743\n",
       "default_sklearn_tokenizer                           0.416767\n",
       "tokenizers/bpe_vocab_size_5000_norm_identity.model  0.415190\n",
       "tokenizers/bpe_vocab_size_1000_norm_identity.model  0.414394\n",
       "tokenizers/bpe_vocab_size_1000_norm_nfkc.model      0.413803\n",
       "tokenizers/unigram_vocab_size_1000_norm_identit...  0.413796"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_metrics_all.groupby('tokenizer')['f1'].median()).sort_values(by=['f1'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizer</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default_sklearn_tokenizer</th>\n",
       "      <td>0.703863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_20000_norm_identity.model</th>\n",
       "      <td>0.698125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_20000_norm_nmt_nfkc_cf.model</th>\n",
       "      <td>0.696095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_20000_norm_nmt_nfkc.model</th>\n",
       "      <td>0.695539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_20000_norm_nfkc.model</th>\n",
       "      <td>0.695539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_20000_norm_nfkc_cf.model</th>\n",
       "      <td>0.694160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_10000_norm_nfkc_cf.model</th>\n",
       "      <td>0.681869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/bpe_vocab_size_10000_norm_nmt_nfkc_cf.model</th>\n",
       "      <td>0.681869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_10000_norm_nfkc.model</th>\n",
       "      <td>0.679319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokenizers/unigram_vocab_size_10000_norm_nmt_nfkc.model</th>\n",
       "      <td>0.679319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          f1\n",
       "tokenizer                                                   \n",
       "default_sklearn_tokenizer                           0.703863\n",
       "tokenizers/unigram_vocab_size_20000_norm_identi...  0.698125\n",
       "tokenizers/unigram_vocab_size_20000_norm_nmt_nf...  0.696095\n",
       "tokenizers/unigram_vocab_size_20000_norm_nmt_nf...  0.695539\n",
       "tokenizers/unigram_vocab_size_20000_norm_nfkc.m...  0.695539\n",
       "tokenizers/unigram_vocab_size_20000_norm_nfkc_c...  0.694160\n",
       "tokenizers/bpe_vocab_size_10000_norm_nfkc_cf.model  0.681869\n",
       "tokenizers/bpe_vocab_size_10000_norm_nmt_nfkc_c...  0.681869\n",
       "tokenizers/unigram_vocab_size_10000_norm_nfkc.m...  0.679319\n",
       "tokenizers/unigram_vocab_size_10000_norm_nmt_nf...  0.679319"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_metrics_all_simple.groupby('tokenizer')['f1'].median()).sort_values(by=['f1'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v36torch1.1.0",
   "language": "python",
   "name": "v36torch1.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
